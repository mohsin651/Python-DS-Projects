{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U08F7iHu-guF"
      },
      "outputs": [],
      "source": [
        "!pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHAIO0YX_Jt5",
        "outputId": "bcd72ba2-34ef-4125-ba5d-9b530ca58fc2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentenceTransformer(\n",
              "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
              "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
              "  (2): Normalize()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = ['This framework generates embeddings for each input sentence',\n",
        "             'sentences are passed as a list of string']\n",
        "\n",
        "embeddings = model.encode(sentences)\n",
        "\n",
        "for sentence, embedding in zip(sentences, embeddings):\n",
        "  print(\"Sentence: \", sentence)\n",
        "  print(\"Embedding: \", embeddings)"
      ],
      "metadata": {
        "id": "W_6Kggmz_-IZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(embeddings)"
      ],
      "metadata": {
        "id": "ek5bipQVAf8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb1 = model.encode(\"I am eating Apple\")\n",
        "emb2 = model.encode(\"I like fruits\")\n",
        "\n",
        "cos_sim = util.cos_sim(emb1, emb2)\n",
        "print(\"Cosine-Similarity: \", cos_sim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwlOr6hzBIY5",
        "outputId": "ce3e8569-85bb-4cd9-ec81-4307a317038e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine-Similarity:  tensor([[0.5398]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = ['A man is eating food.',\n",
        "          'A man is eating a piece of bread.',\n",
        "          'The girl is carrying a baby.',\n",
        "          'A man is riding a horse.',\n",
        "          'A woman is playing violin.',\n",
        "          'Two men pushed carts through the woods.',\n",
        "          'A man is riding a white horse on an enclosed ground.',\n",
        "          'A monkey is playing drums.',\n",
        "          'Someone in a gorilla costume is playing a set of drums.'\n",
        "          ]\n",
        "\n",
        "embeddings = model.encode(sentences)\n",
        "\n",
        "cos_sim = util.cos_sim(embeddings, embeddings)"
      ],
      "metadata": {
        "id": "u9gmsIAQCIEa"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cos_sim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kPkqYWuCjq-",
        "outputId": "3c9bd68e-7445-4aa9-88a4-b2d2f2357241"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.0000,  0.7553, -0.1050,  0.2474, -0.0704, -0.0333,  0.1707,  0.0476,\n",
              "          0.0630],\n",
              "        [ 0.7553,  1.0000, -0.0610,  0.1442, -0.0809, -0.0216,  0.1157,  0.0362,\n",
              "          0.0216],\n",
              "        [-0.1050, -0.0610,  1.0000, -0.1088,  0.0217, -0.0413, -0.0928,  0.0231,\n",
              "          0.0247],\n",
              "        [ 0.2474,  0.1442, -0.1088,  1.0000, -0.0348,  0.0362,  0.7369,  0.0821,\n",
              "          0.1389],\n",
              "        [-0.0704, -0.0809,  0.0217, -0.0348,  1.0000, -0.1654, -0.0592,  0.1961,\n",
              "          0.2564],\n",
              "        [-0.0333, -0.0216, -0.0413,  0.0362, -0.1654,  1.0000,  0.0769, -0.0380,\n",
              "         -0.0895],\n",
              "        [ 0.1707,  0.1157, -0.0928,  0.7369, -0.0592,  0.0769,  1.0000,  0.0495,\n",
              "          0.1191],\n",
              "        [ 0.0476,  0.0362,  0.0231,  0.0821,  0.1961, -0.0380,  0.0495,  1.0000,\n",
              "          0.6433],\n",
              "        [ 0.0630,  0.0216,  0.0247,  0.1389,  0.2564, -0.0895,  0.1191,  0.6433,\n",
              "          1.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(cos_sim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mO5guOJVE8Ag",
        "outputId": "2f2ebf4d-0a86-4d3c-8916-479259f646a2"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = range(len(cos_sim)-1)\n",
        "for n in x:\n",
        "  print(n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUld7wS5F8Vo",
        "outputId": "75eddad9-b73d-43ea-d2d2-b10389366390"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_sentences_combinations = []\n",
        "for i in range(len(cos_sim)-1):\n",
        "  for j in range(i+1, len(cos_sim)):\n",
        "    all_sentences_combinations.append((cos_sim[i][j], i, j))\n",
        "\n",
        "all_sentences_combinations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6n9oIQC3CqIg",
        "outputId": "b74772e0-6ebe-4f29-fdb4-1699075bc3c5"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(tensor(0.7553), 0, 1),\n",
              " (tensor(-0.1050), 0, 2),\n",
              " (tensor(0.2474), 0, 3),\n",
              " (tensor(-0.0704), 0, 4),\n",
              " (tensor(-0.0333), 0, 5),\n",
              " (tensor(0.1707), 0, 6),\n",
              " (tensor(0.0476), 0, 7),\n",
              " (tensor(0.0630), 0, 8),\n",
              " (tensor(-0.0610), 1, 2),\n",
              " (tensor(0.1442), 1, 3),\n",
              " (tensor(-0.0809), 1, 4),\n",
              " (tensor(-0.0216), 1, 5),\n",
              " (tensor(0.1157), 1, 6),\n",
              " (tensor(0.0362), 1, 7),\n",
              " (tensor(0.0216), 1, 8),\n",
              " (tensor(-0.1088), 2, 3),\n",
              " (tensor(0.0217), 2, 4),\n",
              " (tensor(-0.0413), 2, 5),\n",
              " (tensor(-0.0928), 2, 6),\n",
              " (tensor(0.0231), 2, 7),\n",
              " (tensor(0.0247), 2, 8),\n",
              " (tensor(-0.0348), 3, 4),\n",
              " (tensor(0.0362), 3, 5),\n",
              " (tensor(0.7369), 3, 6),\n",
              " (tensor(0.0821), 3, 7),\n",
              " (tensor(0.1389), 3, 8),\n",
              " (tensor(-0.1654), 4, 5),\n",
              " (tensor(-0.0592), 4, 6),\n",
              " (tensor(0.1961), 4, 7),\n",
              " (tensor(0.2564), 4, 8),\n",
              " (tensor(0.0769), 5, 6),\n",
              " (tensor(-0.0380), 5, 7),\n",
              " (tensor(-0.0895), 5, 8),\n",
              " (tensor(0.0495), 6, 7),\n",
              " (tensor(0.1191), 6, 8),\n",
              " (tensor(0.6433), 7, 8)]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sorting list by the highest cosine similarity score\n",
        "all_sentences_combinations = sorted(all_sentences_combinations, key=lambda x:x[0], reverse=True)\n",
        "# all_sentences_combinations\n",
        "print(\"Top 5 most similar pairs: \")\n",
        "for score, i, j in all_sentences_combinations[0:5]:\n",
        "  print(\"{} \\t {} \\t {:.4f}\".format(sentences[i], sentences[j], cos_sim[i][j]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6jTyU13Gajg",
        "outputId": "4576dced-6d5e-439e-bf75-06f92e071412"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 most similar pairs: \n",
            "A man is eating food. \t A man is eating a piece of bread. \t 0.7553\n",
            "A man is riding a horse. \t A man is riding a white horse on an enclosed ground. \t 0.7369\n",
            "A monkey is playing drums. \t Someone in a gorilla costume is playing a set of drums. \t 0.6433\n",
            "A woman is playing violin. \t Someone in a gorilla costume is playing a set of drums. \t 0.2564\n",
            "A man is eating food. \t A man is riding a horse. \t 0.2474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Semantic Search"
      ],
      "metadata": {
        "id": "XBd800jEH07P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"How many models can I host on HuggingFace?\"\n",
        "answer_1 = \"All plans come with unlimited private models and datasets.\"\n",
        "answer_2 = \"AutoNLP is an automatic way to train and deploy state-of-the-art NLP models, seamlessly integrated with the Hugging Face ecosystem.\"\n",
        "answer_3 = \"Based on how much training data and model variants are created, we send you a compute cost and payment link - as low as $10 per job.\"\n",
        "\n",
        "query_embedding = model.encode(question)\n",
        "corpus_embeddings = model.encode([answer_1, answer_2, answer_3])\n",
        "\n",
        "print(util.semantic_search(query_embedding, corpus_embeddings))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMoK7Q2xH3Gv",
        "outputId": "d5ecf670-7c02-492b-acd1-c685df54105b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[{'corpus_id': 0, 'score': 0.35359811782836914}, {'corpus_id': 1, 'score': 0.3143519163131714}, {'corpus_id': 2, 'score': 0.24975530803203583}]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "iNpxwxe5PRmV"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_model = pipeline(\"question-answering\")\n",
        "question = \"How many models can I host on HuggingFace?\"\n",
        "context = \"All plans come with unlimited private models and datasets\"\n",
        "qa_model(question=question, context=context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O72qFPJQPVNV",
        "outputId": "d23d62b1-d32f-45da-8daf-8d127e2541d4"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.7239824533462524, 'start': 20, 'end': 29, 'answer': 'unlimited'}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Corpus with example sentences\n",
        "corpus = ['A man is eating food.',\n",
        "          'A man is eating a piece of bread.',\n",
        "          'Horse is eating grass.',\n",
        "          'A man is eating pasta.',\n",
        "          'A Woman is eating Biryani.',\n",
        "          'The girl is carrying a baby.',\n",
        "          'The baby is carried by the woman',\n",
        "          'A man is riding a horse.',\n",
        "          'A man is riding a white horse on an enclosed ground.',\n",
        "          'A monkey is playing drums.',\n",
        "          'Someone in a gorilla costume is playing a set of drums.',\n",
        "          'A cheetah is running behind its prey.',\n",
        "          'A cheetah chases prey on across a field.',\n",
        "          'The cheetah is chasing a man who is riding the horse.',\n",
        "          'man and women with their baby are watching cheetah in zoo'\n",
        "          ]\n",
        "\n",
        "corpus_embeddings = embedder.encode(corpus)\n",
        "\n",
        "corpus_embeddings = corpus_embeddings / np.linalg.norm(corpus_embeddings, axis=1, keepdims=True)"
      ],
      "metadata": {
        "id": "H9CGwvTiRqbd"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_embeddings[0]"
      ],
      "metadata": {
        "id": "d9wa5TziTcdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clustering_model = KMeans(n_clusters=3)\n",
        "clustering_model.fit(corpus_embeddings)\n",
        "cluster_assignment = clustering_model.labels_\n",
        "print(cluster_assignment)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edtcYJp9TsZk",
        "outputId": "0777b237-a479-4725-a4bf-93e2b38c0906"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 0 1 1 2 2 0 0 0 0 0 0 0 0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence_id, cluster_id in enumerate(cluster_assignment):\n",
        "  print(\"Sentence ID: {} Cluster ID: {}\".format(sentence_id, cluster_id))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVPyPa0dWjFL",
        "outputId": "4484171c-7b58-4746-ea50-b5ee76edd3a3"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence ID: 0 Cluster ID: 1\n",
            "Sentence ID: 1 Cluster ID: 1\n",
            "Sentence ID: 2 Cluster ID: 0\n",
            "Sentence ID: 3 Cluster ID: 1\n",
            "Sentence ID: 4 Cluster ID: 1\n",
            "Sentence ID: 5 Cluster ID: 2\n",
            "Sentence ID: 6 Cluster ID: 2\n",
            "Sentence ID: 7 Cluster ID: 0\n",
            "Sentence ID: 8 Cluster ID: 0\n",
            "Sentence ID: 9 Cluster ID: 0\n",
            "Sentence ID: 10 Cluster ID: 0\n",
            "Sentence ID: 11 Cluster ID: 0\n",
            "Sentence ID: 12 Cluster ID: 0\n",
            "Sentence ID: 13 Cluster ID: 0\n",
            "Sentence ID: 14 Cluster ID: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clustered_sentences = {}\n",
        "for sentence_id, cluster_id in enumerate(cluster_assignment):\n",
        "  if cluster_id not in clustered_sentences:\n",
        "    clustered_sentences[cluster_id] = []\n",
        "\n",
        "  clustered_sentences[cluster_id].append(corpus[sentence_id])\n",
        "\n",
        "clustered_sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f95C38bSVEvs",
        "outputId": "4c3b76f7-d95a-42aa-be12-c784e8b6af77"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: ['A man is eating food.',\n",
              "  'A man is eating a piece of bread.',\n",
              "  'A man is eating pasta.',\n",
              "  'A Woman is eating Biryani.'],\n",
              " 0: ['Horse is eating grass.',\n",
              "  'A man is riding a horse.',\n",
              "  'A man is riding a white horse on an enclosed ground.',\n",
              "  'A monkey is playing drums.',\n",
              "  'Someone in a gorilla costume is playing a set of drums.',\n",
              "  'A cheetah is running behind its prey.',\n",
              "  'A cheetah chases prey on across a field.',\n",
              "  'The cheetah is chasing a man who is riding the horse.',\n",
              "  'man and women with their baby are watching cheetah in zoo'],\n",
              " 2: ['The girl is carrying a baby.', 'The baby is carried by the woman']}"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    }
  ]
}