{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLhDkGIT4mlK",
        "outputId": "81354cb9-434e-4f28-e4f8-77c747492334"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Life': 0, 'dessert': 1, 'eat': 2, 'first': 3, 'is': 4, 'short': 5}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "sentence = 'Life is short, eat dessert first'\n",
        "\n",
        "dc = {s:i for i, s in enumerate(sorted(sentence.replace(',', '').split()))}\n",
        "\n",
        "dc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "sentence_int = torch.tensor(\n",
        "    [dc[s] for s in sentence.replace(',', ' ').split()]\n",
        ")\n",
        "print(sentence_int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHzGukZ246ob",
        "outputId": "50cfa1c8-0bf2-4797-b3c3-bf70ad79bb5a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 4, 5, 2, 1, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 50000\n",
        "\n",
        "torch.manual_seed(123)\n",
        "embed = torch.nn.Embedding(vocab_size, 3)\n",
        "embedded_sentence = embed(sentence_int).detach()\n",
        "\n",
        "print(embedded_sentence)\n",
        "print(embedded_sentence.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBwnFoYv5HtY",
        "outputId": "5590ff9e-78c4-4f65-ca46-0c54f0c0f7a8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.3374, -0.1778, -0.3035],\n",
            "        [ 0.1794,  1.8951,  0.4954],\n",
            "        [ 0.2692, -0.0770, -1.0205],\n",
            "        [-0.2196, -0.3792,  0.7671],\n",
            "        [-0.5880,  0.3486,  0.6603],\n",
            "        [-1.1925,  0.6984, -1.4097]])\n",
            "torch.Size([6, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "d = embedded_sentence.shape[1]\n",
        "\n",
        "d_q, d_k, d_v = 2, 2, 4\n",
        "\n",
        "W_query = torch.nn.Parameter(torch.rand(d_q, d))\n",
        "W_key = torch.nn.Parameter(torch.rand(d_k, d))\n",
        "W_value = torch.nn.Parameter(torch.rand(d_v, d))"
      ],
      "metadata": {
        "id": "a7udJbK_5HnW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W_key.shape, d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNviljj4BKdL",
        "outputId": "3d0ad6cb-e643-4c39-b58d-94af53534f67"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2, 3]), 3)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W_query.shape, x_2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwoRBJTXBs3O",
        "outputId": "31d16a15-ac23-4249-bb9c-bb11099dcce8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2, 3]), torch.Size([3]))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_2 = embedded_sentence[1]\n",
        "query_2 = W_query @ x_2\n",
        "key_2 = W_key @ x_2\n",
        "value_2 = W_value @ x_2\n",
        "\n",
        "print(query_2.shape)\n",
        "print(key_2.shape)\n",
        "print(value_2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfpEenGs_CYI",
        "outputId": "4f66f44b-985d-4298-df06-93acc103d985"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2])\n",
            "torch.Size([2])\n",
            "torch.Size([4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_2, key_2, value_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96HZdGOqEO9e",
        "outputId": "6060ac99-c074-4971-81c1-26adf1006855"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1.1568, 0.6930], grad_fn=<MvBackward0>),\n",
              " tensor([0.3099, 1.0682], grad_fn=<MvBackward0>),\n",
              " tensor([0.5430, 0.7067, 1.7432, 1.7999], grad_fn=<MvBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedded_sentence.shape, W_key.t().shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Impl8mDBFH1j",
        "outputId": "404f7275-2fa7-4483-fc45-a2de3a72d661"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([6, 3]), torch.Size([3, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "queries = embedded_sentence @ W_query.t()\n",
        "keys = embedded_sentence @ W_key.t()\n",
        "values = embedded_sentence @ W_value.t()"
      ],
      "metadata": {
        "id": "B2SbrIHOAASy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"queries.shape:\", queries.shape)\n",
        "print(\"keys.shape:\", keys.shape)\n",
        "print(\"values.shape:\", values.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRhK0-t2AV-K",
        "outputId": "cf16a098-fac3-4108-aca7-682d81fa5e8c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "queries.shape: torch.Size([6, 2])\n",
            "keys.shape: torch.Size([6, 2])\n",
            "values.shape: torch.Size([6, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "values, values.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w01MjKVTFS9T",
        "outputId": "b1a66d8b-e144-4bd2-d23b-2f8aeb20ff96"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-0.1055, -0.1367, -0.2476, -0.2113],\n",
              "         [ 0.5430,  0.7067,  1.7432,  1.7999],\n",
              "         [-0.3177, -0.7453, -0.8191, -0.8921],\n",
              "         [ 0.1516,  0.5015,  0.3204,  0.3821],\n",
              "         [ 0.2330,  0.3515,  0.5692,  0.5221],\n",
              "         [-0.3989, -1.5627, -1.1977, -1.6479]], grad_fn=<MmBackward0>),\n",
              " torch.Size([6, 4]))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "omega24 = query_2.dot(keys[4])\n",
        "omega24"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnOPgf4hFhZy",
        "outputId": "32137341-06a4-4dbb-f3ab-a23fe8a939d2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1836, grad_fn=<DotBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Unnormalized attention weights\n",
        "\n",
        "omega2 = query_2 @ keys.T\n",
        "omega2, d_v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I23zHnzEKzT0",
        "outputId": "6c7a19eb-481d-4360-ea7e-cc4d9be24a93"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-0.0459,  1.0988, -0.5511,  0.2555,  0.1836, -1.5248],\n",
              "        grad_fn=<SqueezeBackward4>),\n",
              " 4)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch.nn.functional as F\n",
        "\n",
        "attention_weights_2 = F.softmax(omega2 / math.sqrt(d_v), dim=0)\n",
        "print(attention_weights_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7EeqN8HOx2k",
        "outputId": "8a4dd7e8-7a3e-4569-b5d6-28526b7511ca"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1585, 0.2809, 0.1231, 0.1842, 0.1777, 0.0756],\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_vector_2 = attention_weights_2 @ values\n",
        "context_vector_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXvfGiroRkKu",
        "outputId": "5db7a794-9c6c-432a-b76d-cedd891c0c7e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1358, 0.1217, 0.4191, 0.4007], grad_fn=<SqueezeBackward4>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "computing normalized attention for all tokens at once - start"
      ],
      "metadata": {
        "id": "x6VXa0jQSCHF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "queries.shape, keys.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjCjIb_zT9NM",
        "outputId": "5d17a0c3-18d8-4d2c-9965-5f6674a708c7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([6, 2]), torch.Size([6, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "omega = queries @ keys.T\n",
        "omega, d_v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GU20q-PORw4W",
        "outputId": "3a0ebdba-53f5-4442-d78a-daf74f754b11"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 2.7697e-03, -6.8030e-02,  3.4104e-02, -1.5821e-02, -1.1244e-02,\n",
              "           9.4798e-02],\n",
              "         [-4.5924e-02,  1.0988e+00, -5.5110e-01,  2.5554e-01,  1.8359e-01,\n",
              "          -1.5248e+00],\n",
              "         [ 1.9828e-02, -8.1986e-01,  4.0784e-01, -1.9043e-01, -1.1284e-01,\n",
              "           1.2138e+00],\n",
              "         [-7.5753e-03,  4.9751e-01, -2.4645e-01,  1.1548e-01,  6.1024e-02,\n",
              "          -7.6006e-01],\n",
              "         [-8.5906e-03,  2.5962e-01, -1.2969e-01,  6.0342e-02,  3.9600e-02,\n",
              "          -3.7221e-01],\n",
              "         [ 4.8586e-02, -2.2343e+00,  1.1102e+00, -5.1887e-01, -2.9842e-01,\n",
              "           3.3368e+00]], grad_fn=<MmBackward0>),\n",
              " 4)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "omega.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpF22VFJUBlh",
        "outputId": "303d7c7c-09f7-4a26-c953-85b3b9959853"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch.nn.functional as F\n",
        "\n",
        "attention_weights = F.softmax(omega / math.sqrt(d_v), dim=0)\n",
        "print(attention_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-OtUnzYR32Q",
        "outputId": "776ca056-b4e3-4a0c-aae8-3ee3a3725e48"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1668, 0.1582, 0.1549, 0.1682, 0.1672, 0.1031],\n",
            "        [0.1627, 0.2835, 0.1156, 0.1926, 0.1843, 0.0459],\n",
            "        [0.1682, 0.1086, 0.1868, 0.1541, 0.1589, 0.1805],\n",
            "        [0.1659, 0.2099, 0.1346, 0.1796, 0.1733, 0.0673],\n",
            "        [0.1658, 0.1863, 0.1427, 0.1747, 0.1715, 0.0817],\n",
            "        [0.1706, 0.0535, 0.2653, 0.1308, 0.1448, 0.5216]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDe8UsZ3UKd3",
        "outputId": "3ed7560a-5ce8-4ea9-e4a8-5df9b337fbbe"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_vectors = attention_weights @ values\n",
        "context_vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOAoXCfOSAWd",
        "outputId": "4293acec-1a8b-4e51-db50-fd59c0589056"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0424, -0.0445,  0.1331,  0.0928],\n",
              "        [ 0.1539,  0.1816,  0.4708,  0.4669],\n",
              "        [-0.0297, -0.2343, -0.0816, -0.1622],\n",
              "        [ 0.0945,  0.0712,  0.2901,  0.2708],\n",
              "        [ 0.0722,  0.0229,  0.2226,  0.1947],\n",
              "        [-0.2277, -0.8819, -0.6666, -0.9104]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "end"
      ],
      "metadata": {
        "id": "R27k1X88SIJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "  def __init__(self, d_in, d_out_kq, d_out_v):\n",
        "    super().__init__()\n",
        "    self.d_out_kq = d_out_kq\n",
        "    self.W_query = nn.Parameter(torch.rand(d_in, d_out_kq))\n",
        "    self.W_key = nn.Parameter(torch.rand(d_in, d_out_kq))\n",
        "    self.W_value = nn.Parameter(torch.rand(d_in, d_out_v))\n",
        "\n",
        "  def forward(self, x):\n",
        "    keys = x @ self.W_key\n",
        "    queries = x @ self.W_query\n",
        "    values = x @ self.W_value\n",
        "\n",
        "    attn_scores = queries @ keys.T # unnormalized attention score\n",
        "    attn_weights = torch.softmax(\n",
        "            attn_scores / self.d_out_kq**0.5, dim=-1\n",
        "    )\n",
        "\n",
        "    context_vec = attn_weights @ values\n",
        "    return context_vec"
      ],
      "metadata": {
        "id": "On7M-jIuUSIG"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "d_in, d_out_kq, d_out_v = 3, 2, 4\n",
        "\n",
        "sa = SelfAttention(d_in, d_out_kq, d_out_v)\n",
        "print(sa(embedded_sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vICUcChLWkEU",
        "outputId": "6e0dbcf6-39d5-42f5-fc29-4b2eb4c77c8d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1564,  0.1028, -0.0763, -0.0764],\n",
            "        [ 0.5313,  1.3607,  0.7891,  1.3110],\n",
            "        [-0.3542, -0.1234, -0.2626, -0.3706],\n",
            "        [ 0.0071,  0.3345,  0.0969,  0.1998],\n",
            "        [ 0.1008,  0.4780,  0.2021,  0.3674],\n",
            "        [-0.5296, -0.2799, -0.4107, -0.6006]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttentionWrapper(nn.Module):\n",
        "  def __init__(self, d_in, d_out_kq, d_out_v, num_heads):\n",
        "    super().__init__()\n",
        "    self.heads = nn.ModuleList(\n",
        "        [SelfAttention(d_in, d_out_kq, d_out_v)\n",
        "        for _ in range(num_heads)]\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return torch.cat([head(x) for head in self.heads], dim=-1)"
      ],
      "metadata": {
        "id": "KmyX8FambSc2"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "d_in, d_out_kq, d_out_v = 3, 2, 1\n",
        "\n",
        "sa = SelfAttention(d_in, d_out_kq, d_out_v)\n",
        "print(sa(embedded_sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PgjuAibb-9G",
        "outputId": "804ce61c-6c0e-43a0-ad2a-f424a35b1d55"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0185],\n",
            "        [ 0.4003],\n",
            "        [-0.1103],\n",
            "        [ 0.0668],\n",
            "        [ 0.1180],\n",
            "        [-0.1827]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "block_size = embedded_sentence.shape[1]\n",
        "mha = MultiHeadAttentionWrapper(\n",
        "    d_in, d_out_kq, d_out_v, num_heads=4\n",
        ")\n",
        "\n",
        "context_vecs = mha(embedded_sentence)\n",
        "\n",
        "print(context_vecs)\n",
        "print(context_vecs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alP5LkNWcgL_",
        "outputId": "6d64a2d5-ea82-42e9-d7e6-67757d009a96"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0185,  0.0170,  0.1999, -0.0860],\n",
            "        [ 0.4003,  1.7137,  1.3981,  1.0497],\n",
            "        [-0.1103, -0.1609,  0.0079, -0.2416],\n",
            "        [ 0.0668,  0.3534,  0.2322,  0.1008],\n",
            "        [ 0.1180,  0.6949,  0.3157,  0.2807],\n",
            "        [-0.1827, -0.2060, -0.2393, -0.3167]], grad_fn=<CatBackward0>)\n",
            "torch.Size([6, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "cross-attention"
      ],
      "metadata": {
        "id": "lNGV76gmE99h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CrossAttention(nn.Module):\n",
        "  def __init__(self, d_in, d_out_kq, d_out_v):\n",
        "    super().__init__()\n",
        "    self.d_out_kq = d_out_kq\n",
        "    self.W_query = nn.Parameter(torch.rand(d_in, d_out_kq))\n",
        "    self.W_key = nn.Parameter(torch.rand(d_in, d_out_kq))\n",
        "    self.W_value = nn.Parameter(torch.rand(d_in, d_out_v))\n",
        "\n",
        "  def forward(self, x_1, x_2): #x1-> input from decoder, x2-> input encoder\n",
        "    queries_1 = x_1 @ self.W_query #comes from decoder\n",
        "    keys_2 = x_2 @ self.W_key #comes from encoder\n",
        "    values_2 = x_2 @ self.W_value #comes from encoder\n",
        "\n",
        "    attn_scores = queries_1 @ keys_2.T\n",
        "    attn_weights = torch.softmax(\n",
        "        attn_scores/math.sqrt(self.d_out_kq), dim=-1\n",
        "    )\n",
        "    context_vec = attn_weights @ values_2\n",
        "    return context_vec"
      ],
      "metadata": {
        "id": "LkrsvYDNE__D"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "d_in, d_out_kq, d_out_v = 3, 2, 4\n",
        "\n",
        "crossattn = CrossAttention(d_in, d_out_kq, d_out_v)\n",
        "\n",
        "first_input = embedded_sentence\n",
        "second_input = torch.rand(8, d_in)\n",
        "\n",
        "print(\"First input shape:\", first_input.shape)\n",
        "print(\"Second input shape:\", second_input.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7suxXMrIYNi",
        "outputId": "86c214af-7f1c-4035-dd8b-7b6099530d70"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First input shape: torch.Size([6, 3])\n",
            "Second input shape: torch.Size([8, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_vectors = crossattn(first_input, second_input)\n",
        "\n",
        "print(context_vectors)\n",
        "print(\"Output Shape: \", context_vectors.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-lOi2jBIx8f",
        "outputId": "4e5061d8-2f9e-4863-932f-32b58646c12d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4231, 0.8665, 0.6503, 1.0042],\n",
            "        [0.4874, 0.9718, 0.7359, 1.1353],\n",
            "        [0.4054, 0.8359, 0.6258, 0.9667],\n",
            "        [0.4357, 0.8886, 0.6678, 1.0311],\n",
            "        [0.4429, 0.9006, 0.6775, 1.0460],\n",
            "        [0.3860, 0.8021, 0.5985, 0.9250]], grad_fn=<MmBackward0>)\n",
            "Output Shape:  torch.Size([6, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "causal attention (masked attention)"
      ],
      "metadata": {
        "id": "40utL8BcWMFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "d_in, d_out_kq, d_out_v = 3, 2, 4\n",
        "\n",
        "W_query = nn.Parameter(torch.rand(d_in, d_out_kq))\n",
        "W_keq = nn.Parameter(torch.rand(d_in, d_out_kq))\n",
        "W_value = nn.Parameter(torch.rand(d_in, d_out_v))\n",
        "\n",
        "x = embedded_sentence\n",
        "\n",
        "keys = x @ W_key\n",
        "queries = x @ W_query\n",
        "values = x @ W_value\n",
        "\n",
        "attn_scores = queries @ keys.T\n",
        "\n",
        "print(attn_scores)\n",
        "print(attn_scores.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xN8wnKwbWO4-",
        "outputId": "05edb573-b3b6-4303-f13e-62ea371166dd"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0613, -0.3491,  0.1443, -0.0437, -0.1303,  0.1076],\n",
            "        [-0.6004,  3.4707, -1.5023,  0.4991,  1.2903, -1.3374],\n",
            "        [ 0.2432, -1.3934,  0.5869, -0.1851, -0.5191,  0.4730],\n",
            "        [-0.0794,  0.4487, -0.1807,  0.0518,  0.1677, -0.1197],\n",
            "        [-0.1510,  0.8626, -0.3597,  0.1112,  0.3216, -0.2787],\n",
            "        [ 0.4344, -2.5037,  1.0740, -0.3509, -0.9315,  0.9265]],\n",
            "       grad_fn=<MmBackward0>)\n",
            "torch.Size([6, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights = torch.softmax(attn_scores/math.sqrt(d_out_kq), dim=1)\n",
        "print(attn_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NK4iUDCXY_7",
        "outputId": "690b9a04-c6dc-4c85-817b-a95b52a5c62e"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1772, 0.1326, 0.1879, 0.1645, 0.1547, 0.1831],\n",
            "        [0.0386, 0.6870, 0.0204, 0.0840, 0.1470, 0.0229],\n",
            "        [0.1965, 0.0618, 0.2506, 0.1452, 0.1146, 0.2312],\n",
            "        [0.1505, 0.2187, 0.1401, 0.1651, 0.1793, 0.1463],\n",
            "        [0.1347, 0.2758, 0.1162, 0.1621, 0.1881, 0.1231],\n",
            "        [0.1973, 0.0247, 0.3102, 0.1132, 0.0751, 0.2794]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = attn_scores.shape[0]\n",
        "mask_simple = torch.tril(torch.ones(block_size, block_size))\n",
        "print(mask_simple)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZ9gMKx-ZUdO",
        "outputId": "46ec489a-14fb-4e52-db83-522acf85fb05"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 0.],\n",
            "        [1., 1., 1., 1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_simple = attn_weights * mask_simple\n",
        "masked_simple"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxK255qhZ7G2",
        "outputId": "c00cbde0-f073-4b85-83cb-2bcbe99c550f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1772, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0386, 0.6870, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1965, 0.0618, 0.2506, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1505, 0.2187, 0.1401, 0.1651, 0.0000, 0.0000],\n",
              "        [0.1347, 0.2758, 0.1162, 0.1621, 0.1881, 0.0000],\n",
              "        [0.1973, 0.0247, 0.3102, 0.1132, 0.0751, 0.2794]],\n",
              "       grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "row_sums = masked_simple.sum(dim=1, keepdim=True)\n",
        "masked_simple_norm = masked_simple / row_sums\n",
        "print(masked_simple_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93P5o1u8hHW2",
        "outputId": "c1503811-c125-427b-8f11-4ba735b6c5ae"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0532, 0.9468, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3862, 0.1214, 0.4924, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2232, 0.3242, 0.2078, 0.2449, 0.0000, 0.0000],\n",
            "        [0.1536, 0.3145, 0.1325, 0.1849, 0.2145, 0.0000],\n",
            "        [0.1973, 0.0247, 0.3102, 0.1132, 0.0751, 0.2794]],\n",
            "       grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    }
  ]
}